{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "109OkWShbHlY"
      },
      "source": [
        "**AAI-590: Capstone Project**\n",
        "\n",
        "By: Aditya, Deepak and Rajesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uKQsBsKbfGI",
        "outputId": "76947ed1-5470-4d9c-f9a2-58ab5d384b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# LIBRARY IMPORTS\n",
        "# ================================================================================\n",
        "# Import essential libraries for data processing, machine learning, and visualization\n",
        "\n",
        "# Data manipulation and numerical operations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# JSON handling and type annotations\n",
        "import json\n",
        "from typing import List, Tuple, Dict, Set\n",
        "\n",
        "# Machine learning and model evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.utils import class_weight\n",
        "import joblib\n",
        "\n",
        "# Gradio interface and image processing\n",
        "import gradio as gr\n",
        "import io\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Google Drive integration for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Add custom module path for helper functions\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/AAI-590/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMyaxe42cAnr"
      },
      "source": [
        "## Define Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwrjTSD4kPbV",
        "outputId": "e598d8f0-5a6b-4561-cdfc-089b1d411795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/AAI-590/text_helpers.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/AAI-590/text_helpers.py\n",
        "\n",
        "# ================================================================================\n",
        "# TEXT PREPROCESSING HELPER FUNCTIONS\n",
        "# ================================================================================\n",
        "# This module contains utility functions for text preprocessing and cleaning\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from typing import *\n",
        "\n",
        "def build_text(title: str, review: str) -> str:\n",
        "    \"\"\"\n",
        "    Concatenate review title and review text into a single lowercase string.\n",
        "    \n",
        "    Args:\n",
        "        title (str): Review title\n",
        "        review (str): Review text content\n",
        "        \n",
        "    Returns:\n",
        "        str: Combined and lowercased text with title and review separated by newline\n",
        "    \"\"\"\n",
        "    return (str(title or \"\") + \" \\n\" + str(review or \"\")).strip().lower()\n",
        "\n",
        "def safe_get(row: pd.Series, col: str) -> str:\n",
        "    \"\"\"\n",
        "    Safely extract and clean text from a DataFrame row.\n",
        "    \n",
        "    Handles missing values (NaN) and removes non-English characters while preserving\n",
        "    basic punctuation. Keeps only: letters, numbers, spaces, and .,!?-\n",
        "    \n",
        "    Args:\n",
        "        row (pd.Series): DataFrame row\n",
        "        col (str): Column name to extract\n",
        "        \n",
        "    Returns:\n",
        "        str: Cleaned text string, empty string if value is missing\n",
        "    \"\"\"\n",
        "    value = row[col] if col in row and not pd.isna(row[col]) else \"\"\n",
        "    if isinstance(value, str):\n",
        "        # Keep only English letters, numbers, spaces, and basic punctuation\n",
        "        return re.sub(r'[^a-zA-Z0-9\\s.,!?-]', '', value)\n",
        "    return str(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv7Lk25AkU-a",
        "outputId": "04358f91-c76d-4c3b-fb8d-61e84f4d8189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build_text and safe_get functions imported from text_helpers.py\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# IMPORT HELPER FUNCTIONS\n",
        "# ================================================================================\n",
        "# Load custom text preprocessing functions from the helper module\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/AAI-590/')\n",
        "from text_helpers import build_text, safe_get\n",
        "\n",
        "print(\"build_text and safe_get functions imported from text_helpers.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3haqHe7ZcdqQ"
      },
      "source": [
        "## Define Business Rules for Attribute Extraction\n",
        "\n",
        "This cell creates a comprehensive rule-based system stored in `attribute_rules.py` that defines regex patterns for extracting product attributes from review text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g-G1d9wcWTK",
        "outputId": "8a8c1810-b404-4cc8-b54d-38712aa54bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/AAI-590/attribute_rules.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/AAI-590/attribute_rules.py\n",
        "\n",
        "# ================================================================================\n",
        "# ATTRIBUTE EXTRACTION RULES\n",
        "# ================================================================================\n",
        "# Comprehensive regex-based rules for extracting product attributes from reviews\n",
        "# Each tuple contains: (regex_pattern, attribute_tag)\n",
        "# These rules cover multiple product categories including clothing, footwear, and accessories\n",
        "\n",
        "rules_list = [\n",
        "    # ============================================================================\n",
        "    # WARMTH ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(warmest|toasty|cozy|very warm|super warm|warm & toasty|warm hat)\\b\", \"Warmth:high\"),\n",
        "    (r\"\\b(keeps .* head warm|keeps .* ears warm|kept .* head warm|keeps me warm|kept me warm)\\b\", \"Warmth:high\"),\n",
        "    (r\"\\b(not warm|isn't warm|cold passes through|wind (?:passes|blows) right through|doesn't keep .* warm|not as warm)\\b\", \"Warmth:low\"),\n",
        "    (r\"\\b(wind (?:blocking|proof)|blocks the wind)\\b\", \"Warmth:wind_blocking\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # FIT & SIZING ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(too tight|very tight|super tight|tight fit|gives me headaches)\\b\", \"Fit:tight\"),\n",
        "    (r\"\\b(too small|runs small|child'?s size|youth size|smaller than|tiny)\\b\", \"Fit:small\"),\n",
        "    (r\"\\b(snug fit|snug)\\b\", \"Fit:snug\"),\n",
        "    (r\"\\b(too loose|loose fit|baggy|very loose|ill[- ]?fitting|slides off|slips off)\\b\", \"Fit:loose\"),\n",
        "    (r\"\\b(rides up|creeps up|shrinks off my head)\\b\", \"Fit:rides_up\"),\n",
        "    (r\"\\b(too long|very long|super long|tall|conehead|pointy|smurf|extra fabric|excess fabric|sticks up|floppy|looks like a cone|cat in the hat)\\b\", \"Fit:excess_length\"),\n",
        "    (r\"\\b(one size fits all|osfa)\\b\", \"Sizing:one_size\"),\n",
        "    (r\"\\b(inconsistent size|quality control|different sizes|wildly different sizes|manufacturing oversight)\\b\", \"Sizing:inconsistent\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # COLOR ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(color (?:exactly|as pictured|as described|true to (?:pic|picture|site)))\\b\", \"Color:accurate\"),\n",
        "    (r\"\\b(color (?:wrong|off|not .* (?:as pictured|as described)|different in person)|looks (?:brown|dark) not .* (?:purple|burgundy|blackberry)|blackberry .* brown)\\b\", \"Color:off\"),\n",
        "    (r\"\\b(too bright|very bright|hunter orange|blaze orange|brite lime|high(?:-)?vis|hi(?:-)?vis|osha)\\b\", \"Color:bright_hi_vis\"),\n",
        "    (r\"\\b(darker than|much darker|very dark|almost black)\\b\", \"Color:darker\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # MATERIAL & TEXTURE ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(soft|super soft|so soft)\\b\", \"Material:soft\"),\n",
        "    (r\"\\b(itchy|makes my forehead itchy|not soft)\\b\", \"Material:itchy\"),\n",
        "    (r\"\\b(thin|not thick|light ?weight)\\b\", \"Material:thin\"),\n",
        "    (r\"\\b(thick|hefty knit|double layer)\\b\", \"Material:thick\"),\n",
        "    (r\"\\bacrylic\\b\", \"Material:acrylic\"),\n",
        "    (r\"\\b(quality (?:went down|declined|poor)|worse quality|quality change|not the same quality)\\b\", \"Quality:declined\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # STRETCH ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(stretches (?:well|easily)|good stretch)\\b\", \"Stretch:good\"),\n",
        "    (r\"\\b(doesn't stretch|won't stretch)\\b\", \"Stretch:poor\"),\n",
        "    (r\"\\b(stretched out|gets baggy|stretch(?:es)? out easy)\\b\", \"Stretch:stretches_out\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # DURABILITY & CONSTRUCTION ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(durable|lasts forever|last for years|very well made|well made)\\b\", \"Durability:high\"),\n",
        "    (r\"\\b(stitching (?:crooked|came out)|logo (?:fell off|upside down|incorrect)|hole|defective|poor quality control)\\b\", \"Durability:issues\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # STYLE & USE CASE ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(cute|stylish|looks great|fashion|trendy)\\b\", \"Style:cute\"),\n",
        "    (r\"\\b(classic|staple|iconic)\\b\", \"Style:classic\"),\n",
        "    (r\"\\b(hard hat|jobsite|work|warehouse|freezer|construction|farm)\\b\", \"Use:work\"),\n",
        "    (r\"\\b(hunt(?:ing)?|blaze orange)\\b\", \"Use:hunting\"),\n",
        "    (r\"\\b(ski(?:ing)?|snowboard|hiking|mountaineering|outdoors|camping)\\b\", \"Use:outdoors\"),\n",
        "    (r\"\\b(gift|present|stocking stuffer)\\b\", \"Use:gift\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # COUNTRY OF ORIGIN\n",
        "    # ============================================================================\n",
        "    (r\"made in usa\", \"Made_in:USA\"),\n",
        "    (r\"made in canada\", \"Made_in:Canada\"),\n",
        "    (r\"made in china\", \"Made_in:China\"),\n",
        "    (r\"made in vietnam\", \"Made_in:Vietnam\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # PRICE & SERVICE ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\b(overpriced|pricey)\\b\", \"Price:overpriced\"),\n",
        "    (r\"\\b(great price|fair price|good price|value)\\b\", \"Price:value\"),\n",
        "    (r\"\\b(fast shipping|arrived quickly|quick delivery)\\b\", \"Shipping:fast\"),\n",
        "    (r\"\\b(slow shipping|arrived late|took (?:weeks|long)|delivery .* (?:late|slow))\\b\", \"Shipping:slow\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # CARE INSTRUCTIONS\n",
        "    # ============================================================================\n",
        "    (r\"\\b(hand wash|do not (?:machine )?dry|shrinks|shrinkage|wash(?:es)? well|launder)\\b\", \"Care:notes\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # PRODUCT TYPES (Footwear & Accessories)\n",
        "    # ============================================================================\n",
        "    (r\"\\bodor[- ]?x\\b|\\bodor[- ]?fighting foot powder\\b|\\bfoot powder\\b\", \"Product:FootPowder\"),\n",
        "    (r\"\\binsoles?\\b|\\bshoe inserts?\\b\", \"Product:Insole\"),\n",
        "    (r\"\\bheel (?:cushion|cup)s?\\b\", \"Product:HeelCushion\"),\n",
        "    (r\"\\blaces?\\b|\\bshoelaces?\\b\", \"Product:Laces\"),\n",
        "    (r\"\\bshoe ?horn\\b\", \"Product:ShoeHorn\"),\n",
        "    (r\"\\bshoe trees?\\b\", \"Product:ShoeTrees\"),\n",
        "\n",
        "    # ============================================================================\n",
        "    # ODOR & SWEAT CONTROL (Footwear-specific)\n",
        "    # ============================================================================\n",
        "    (r\"\\b(kills the funk|odor fighter|no more (?:stinky|smelly) feet|\"\n",
        "      r\"eliminat(?:e|es|ed) odor|destroy(?:s|ed)? odor|neutraliz(?:e|es|ed)|\"\n",
        "      r\"odor[- ]?control)\\b\", \"OdorControl:effective\"),\n",
        "    (r\"\\b(?:odor|smell) (?:still|worse|bad)|does(?:n't| not) (?:work|help).*(?:odor|smell)\\b\", \"OdorControl:ineffective\"),\n",
        "    (r\"\\b(keeps|kept) (?:feet|socks) (?:dry|cool)\\b\", \"Sweat:dry\"),\n",
        "    (r\"\\b(?:too|very|brutally) dry|dries out (?:feet|skin)\\b\", \"Sweat:overdry\"),\n",
        "    (r\"\\b(messy|powder footprints?|white footprint|powder all over)\\b\", \"Powder:messy\"),\n",
        "    (r\"\\b(light(?:ly)?|mild) (?:scent|smell)\\b\", \"Scent:mild\"),\n",
        "    (r\"\\b(strong|heavy) (?:scent|smell)\\b\", \"Scent:strong\"),\n",
        "    (r\"\\b(makes .*feet.* sweaty|feet (?:sweaty|hot))\\b\", \"Sweat:increased\"),\n",
        "\n",
        "    # ============================================================================\n",
        "    # COMFORT & SUPPORT (Footwear-specific)\n",
        "    # ============================================================================\n",
        "    (r\"\\b(walking on (?:air|clouds|pillows)|cushion(?:ing)?|cushy|massaging gel|\"\n",
        "      r\"comfortable|comfort)\\b\", \"Comfort:high\"),\n",
        "    (r\"\\b(reduce(?:s|d)? (?:fatigue|tired)|more (?:energy|support)|support(?:ive)?)\\b\", \"Support:good\"),\n",
        "    (r\"\\b(plantar fasciitis|heel pain relief|help(?:s)? my heels)\\b\", \"Health:heel_pain_relief\"),\n",
        "    (r\"\\barch support\\b\", \"Support:arch\"),\n",
        "    (r\"\\b(no arch support|arch too (?:low|high)|painful arch support)\\b\", \"Support:arch_issue\"),\n",
        "    (r\"\\b(hard|rigid|too (?:hard|stiff)|uncomfortable|painful)\\b\", \"Comfort:low\"),\n",
        "\n",
        "    # ============================================================================\n",
        "    # FIT & INSTALLATION (Footwear-specific)\n",
        "    # ============================================================================\n",
        "    (r\"\\b(trim to size|cut to size|easy to trim|sizing guide)\\b\", \"Fit:trim_to_size\"),\n",
        "    (r\"\\b(too thick|bulky|makes shoes tight|snug fit|no room|raised heel)\\b\", \"Fit:too_thick\"),\n",
        "    (r\"\\b(not wide enough|narrow|size mismark(?:ed)?|wrong size)\\b\", \"Fit:size_issue\"),\n",
        "    (r\"\\b(slid(?:e|es|ing)|moves?|bunch(?:es)? up|curl(?:s|ed)|does(?:n't| not) stay in place)\\b\", \"Fit:moves_in_shoe\"),\n",
        "    (r\"\\b(squeak|gurgle|nois(?:e|y))\\b\", \"Fit:noise\"),\n",
        "\n",
        "    # ============================================================================\n",
        "    # DURABILITY (Footwear-specific)\n",
        "    # ============================================================================\n",
        "    (r\"\\b(fell apart|separat(?:e|ed)|delaminat(?:e|ed)|\"\n",
        "      r\"gel (?:leaked|disintegrated|broke|flattened)|\"\n",
        "      r\"wore out (?:quickly|fast)|poor lifespan|quality (?:declined|down))\\b\", \"Durability:issues\"),\n",
        "    (r\"\\b(last(?:s|ed) (?:weeks|months|years)|durable)\\b\", \"Durability:high\"),\n",
        "\n",
        "    # ============================================================================\n",
        "    # USE CONTEXTS (Profession & Activity)\n",
        "    # ============================================================================\n",
        "    (r\"\\b(work boots?|steel toe|warehouse|factory|concrete|long shift|12 ?hours?|\"\n",
        "      r\"standing all day|on my feet all day)\\b\", \"Use:work_long_hours\"),\n",
        "    (r\"\\b(hiking|trail|outdoors|boots)\\b\", \"Use:hiking\"),\n",
        "    (r\"\\b(nurse|teacher|barista|server|construction|landscap(?:er|ing))\\b\", \"Use:profession\"),\n",
        "    (r\"\\b(dress shoes|heels?|cowboy boots|rain boots|sneakers|tennis shoes|keds|converse)\\b\", \"Use:shoe_type\"),\n",
        "\n",
        "    # ============================================================================\n",
        "    # LACES ATTRIBUTES\n",
        "    # ============================================================================\n",
        "    (r\"\\bstay tied\\b\", \"Laces:stay_tied\"),\n",
        "    (r\"\\bthin\\b\", \"Laces:thin\"),\n",
        "    (r\"\\bwaxed\\b\", \"Laces:waxed\"),\n",
        "\n",
        "    # ============================================================================\n",
        "    # SHOE ACCESSORIES\n",
        "    # ============================================================================\n",
        "    (r\"\\bshoe ?horn\\b.*\\b(?:useless|spring).*(?:rigid|support)|\\bspring\\b.*\\bdoes(?:n't| not) allow support\\b\", \"ShoeHorn:ineffective\"),\n",
        "    (r\"\\bprevent wrinkles|stretch the length\\b\", \"ShoeTrees:effective\"),\n",
        "    \n",
        "    # ============================================================================\n",
        "    # RECOMMENDATION\n",
        "    # ============================================================================\n",
        "    (r\"\\b(highly recommend|would recommend|recommend to|definitely recommend)\\b\", \"Recommendation:recommend\"),\n",
        "    (r\"\\b(would not recommend|won't recommend|not recommend)\\b\", \"Recommendation:not_recommend\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLWVr09rc0sd"
      },
      "source": [
        "## Load and Prepare Data\n",
        "\n",
        "\n",
        "Loading the two CSV files into DataFrames, selecting relevant columns, add the 'Category' column, and concatenate them into a single `df_selected` DataFrame. Ensure consistent use of `df_selected` throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R8X5DQoncslJ",
        "outputId": "4f1e8047-7989-48ce-916e-5f47ee0a1570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame loaded successfully.\n",
            "First 5 rows of the DataFrame:\n",
            "          Id                                   CID SourceClient  \\\n",
            "0  314505599  43bb9f86-6037-5f19-8dc4-06e2f59bb9f2     carhartt   \n",
            "1  311030383  e2655a8b-e7d1-56e2-9196-193c93bd2dbf     carhartt   \n",
            "2  311030373  287c81dc-05c3-5b2a-94b5-4c39e389cc21     carhartt   \n",
            "3  276723966  5d33f88d-c9ec-52bb-ad02-7f59df3c8dd5     carhartt   \n",
            "4  276451217  c146de06-eb01-5b8a-be47-c2574b577259     carhartt   \n",
            "\n",
            "               LastModeratedTime           LastModificationTime  ProductId  \\\n",
            "0  2024-07-17T14:46:11.000+00:00  2024-07-17T14:46:11.000+00:00     328283   \n",
            "1  2024-06-04T14:47:21.000+00:00  2024-06-04T14:47:21.000+00:00     328283   \n",
            "2  2024-06-04T14:47:21.000+00:00  2024-06-04T14:47:21.000+00:00     328283   \n",
            "3  2024-04-15T14:15:47.000+00:00  2024-04-15T14:15:47.000+00:00     328283   \n",
            "4  2024-04-10T14:46:17.000+00:00  2024-04-10T14:46:17.000+00:00     328283   \n",
            "\n",
            "  OriginalProductName    UserLocation                   AuthorId  \\\n",
            "0  Knit Cuffed Beanie  Tuscaloosa, AL  2st38jplc7lyycl8fefglpm6q   \n",
            "1  Knit Cuffed Beanie       Logan, UT  m3llfwogvf7i2s4meymcndiwb   \n",
            "2  Knit Cuffed Beanie    Sherwood, OR  etj4yrbwm0elx4b0c0t9rpaup   \n",
            "3  Knit Cuffed Beanie             NaN  hk7wtwgmrn53ry0ursebxbr8q   \n",
            "4  Knit Cuffed Beanie             NaN  ai5jj6behxzu7gerfxf7pnp8o   \n",
            "\n",
            "  ContentLocale  ...  TotalPositiveFeedbackCount  SubmissionId  \\\n",
            "0         en_US  ...                           0           NaN   \n",
            "1         en_US  ...                           0           NaN   \n",
            "2         en_US  ...                           0           NaN   \n",
            "3         en_US  ...                           0           NaN   \n",
            "4         en_US  ...                           0           NaN   \n",
            "\n",
            "   SecondaryRatings BadgesOrder  Photos  ClientResponses  \\\n",
            "0                {}          []      []               []   \n",
            "1                {}          []      []               []   \n",
            "2                {}          []      []               []   \n",
            "3                {}          []      []               []   \n",
            "4                {}          []      []               []   \n",
            "\n",
            "   TotalNegativeFeedbackCount  SecondaryRatingsOrder  \\\n",
            "0                           0                     []   \n",
            "1                           0                     []   \n",
            "2                           0                     []   \n",
            "3                           0                     []   \n",
            "4                           0                     []   \n",
            "\n",
            "  InappropriateFeedbackList Pros  \n",
            "0                        []  NaN  \n",
            "1                        []  NaN  \n",
            "2                        []  NaN  \n",
            "3                        []  NaN  \n",
            "4                        []  NaN  \n",
            "\n",
            "[5 rows x 49 columns]\n",
            "\n",
            "Column names and their data types:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43541 entries, 0 to 43540\n",
            "Data columns (total 49 columns):\n",
            " #   Column                           Non-Null Count  Dtype  \n",
            "---  ------                           --------------  -----  \n",
            " 0   Id                               43541 non-null  int64  \n",
            " 1   CID                              43541 non-null  object \n",
            " 2   SourceClient                     43541 non-null  object \n",
            " 3   LastModeratedTime                43541 non-null  object \n",
            " 4   LastModificationTime             43541 non-null  object \n",
            " 5   ProductId                        43541 non-null  int64  \n",
            " 6   OriginalProductName              43541 non-null  object \n",
            " 7   UserLocation                     26079 non-null  object \n",
            " 8   AuthorId                         43541 non-null  object \n",
            " 9   ContentLocale                    43541 non-null  object \n",
            " 10  IsFeatured                       43541 non-null  bool   \n",
            " 11  TotalInappropriateFeedbackCount  43541 non-null  int64  \n",
            " 12  IsSyndicated                     43541 non-null  bool   \n",
            " 13  SyndicationSource                43285 non-null  object \n",
            " 14  TotalClientResponseCount         43541 non-null  int64  \n",
            " 15  TotalCommentCount                43541 non-null  int64  \n",
            " 16  Rating                           43541 non-null  int64  \n",
            " 17  IsRatingsOnly                    43541 non-null  bool   \n",
            " 18  ModerationStatus                 43541 non-null  object \n",
            " 19  SubmissionTime                   43541 non-null  object \n",
            " 20  ReviewText                       43420 non-null  object \n",
            " 21  Title                            36868 non-null  object \n",
            " 22  UserNickname                     41910 non-null  object \n",
            " 23  AdditionalFields                 43541 non-null  object \n",
            " 24  CampaignId                       256 non-null    object \n",
            " 25  TotalFeedbackCount               43541 non-null  int64  \n",
            " 26  Helpfulness                      32 non-null     float64\n",
            " 27  RatingRange                      43541 non-null  int64  \n",
            " 28  Badges                           43541 non-null  object \n",
            " 29  ProductRecommendationIds         43541 non-null  object \n",
            " 30  ContextDataValues                43541 non-null  object \n",
            " 31  IsRecommended                    15781 non-null  object \n",
            " 32  ContextDataValuesOrder           43541 non-null  object \n",
            " 33  TagDimensionsOrder               43541 non-null  object \n",
            " 34  AdditionalFieldsOrder            43541 non-null  object \n",
            " 35  Cons                             0 non-null      float64\n",
            " 36  TagDimensions                    43541 non-null  object \n",
            " 37  Videos                           43541 non-null  object \n",
            " 38  CommentIds                       43541 non-null  object \n",
            " 39  TotalPositiveFeedbackCount       43541 non-null  int64  \n",
            " 40  SubmissionId                     256 non-null    object \n",
            " 41  SecondaryRatings                 43541 non-null  object \n",
            " 42  BadgesOrder                      43541 non-null  object \n",
            " 43  Photos                           43541 non-null  object \n",
            " 44  ClientResponses                  43541 non-null  object \n",
            " 45  TotalNegativeFeedbackCount       43541 non-null  int64  \n",
            " 46  SecondaryRatingsOrder            43541 non-null  object \n",
            " 47  InappropriateFeedbackList        43541 non-null  object \n",
            " 48  Pros                             0 non-null      float64\n",
            "dtypes: bool(3), float64(3), int64(10), object(33)\n",
            "memory usage: 15.4+ MB\n",
            "None\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: nan",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-322e8d21-4deb-4d13-bb44-42a28565353c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SourceClient</th>\n",
              "      <th>OriginalProductName</th>\n",
              "      <th>Title</th>\n",
              "      <th>ReviewText</th>\n",
              "      <th>Rating</th>\n",
              "      <th>IsRecommended</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>carhartt</td>\n",
              "      <td>Knit Cuffed Beanie</td>\n",
              "      <td>Great hat</td>\n",
              "      <td>These hats are great. They are warm, comfortab...</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Women_Clothing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>carhartt</td>\n",
              "      <td>Knit Cuffed Beanie</td>\n",
              "      <td>Awkward fit, miss my old Carhartt beanie</td>\n",
              "      <td>I ordered this beanie to replace a Carhartt be...</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Women_Clothing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>carhartt</td>\n",
              "      <td>Knit Cuffed Beanie</td>\n",
              "      <td>NaN</td>\n",
              "      <td>But for these beanies and they all were great....</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Women_Clothing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>carhartt</td>\n",
              "      <td>Knit Cuffed Beanie</td>\n",
              "      <td>Beanie2024Chicago</td>\n",
              "      <td>My son immediately worn his beanie to work. Ap...</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Women_Clothing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>carhartt</td>\n",
              "      <td>Knit Cuffed Beanie</td>\n",
              "      <td>Best Beanie</td>\n",
              "      <td>Great fit and fast shipping. My Daughters need...</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Women_Clothing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-322e8d21-4deb-4d13-bb44-42a28565353c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-322e8d21-4deb-4d13-bb44-42a28565353c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-322e8d21-4deb-4d13-bb44-42a28565353c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f54b8b51-a905-4885-b8ec-cab526b36b26\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f54b8b51-a905-4885-b8ec-cab526b36b26')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f54b8b51-a905-4885-b8ec-cab526b36b26 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  SourceClient OriginalProductName                                     Title  \\\n",
              "0     carhartt  Knit Cuffed Beanie                                 Great hat   \n",
              "1     carhartt  Knit Cuffed Beanie  Awkward fit, miss my old Carhartt beanie   \n",
              "2     carhartt  Knit Cuffed Beanie                                       NaN   \n",
              "3     carhartt  Knit Cuffed Beanie                         Beanie2024Chicago   \n",
              "4     carhartt  Knit Cuffed Beanie                               Best Beanie   \n",
              "\n",
              "                                          ReviewText  Rating IsRecommended  \\\n",
              "0  These hats are great. They are warm, comfortab...       5           NaN   \n",
              "1  I ordered this beanie to replace a Carhartt be...       2           NaN   \n",
              "2  But for these beanies and they all were great....       5           NaN   \n",
              "3  My son immediately worn his beanie to work. Ap...       5           NaN   \n",
              "4  Great fit and fast shipping. My Daughters need...       5           NaN   \n",
              "\n",
              "         Category  \n",
              "0  Women_Clothing  \n",
              "1  Women_Clothing  \n",
              "2  Women_Clothing  \n",
              "3  Women_Clothing  \n",
              "4  Women_Clothing  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# DATA LOADING AND PREPARATION\n",
        "# ================================================================================\n",
        "# Load review datasets from CSV files and combine them into a single DataFrame\n",
        "\n",
        "# Define file paths for the two datasets\n",
        "csv_file_path_1 = '/content/drive/MyDrive/AAI-590/Womens-clothingReviews.csv'\n",
        "csv_file_path_2 = '/content/drive/MyDrive/AAI-590/shoe-care-insolesReviews.csv'\n",
        "\n",
        "# Load datasets into DataFrames\n",
        "df1 = pd.read_csv(csv_file_path_1)\n",
        "df2 = pd.read_csv(csv_file_path_2)\n",
        "\n",
        "print(\"DataFrame loaded successfully.\")\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df1.head())\n",
        "\n",
        "print(\"\\nColumn names and their data types:\")\n",
        "print(df1.info())\n",
        "\n",
        "# Select relevant columns for analysis\n",
        "selected_columns = ['SourceClient', 'OriginalProductName', 'Title', 'ReviewText', 'Rating', 'IsRecommended']\n",
        "\n",
        "# Process first dataset and add category label\n",
        "df_selected1 = df1[selected_columns]\n",
        "df_selected1['Category'] = 'Women_Clothing'\n",
        "\n",
        "# Process second dataset and add category label\n",
        "df_selected2 = df2[selected_columns]\n",
        "df_selected2['Category'] = 'Shoe_insole'\n",
        "\n",
        "# Combine both datasets into a single DataFrame\n",
        "df_selected = pd.concat([df_selected1, df_selected2], ignore_index=True)\n",
        "\n",
        "display(df_selected.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgXECf3GdTQr"
      },
      "source": [
        "## Sentiment Model Training\n",
        "\n",
        "Train a multi-class sentiment classification model using TF-IDF features and Logistic Regression. The model classifies reviews into three categories: positive, neutral, and negative based on ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLRdjDuwdKEn",
        "outputId": "3facb458-8c14-4e9f-c384-e6c2fcce785e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Sentiment classification report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.863     0.952     0.905      1053\n",
            "     neutral      0.655     0.892     0.755       517\n",
            "    positive      0.994     0.957     0.975      7881\n",
            "\n",
            "    accuracy                          0.953      9451\n",
            "   macro avg      0.837     0.933     0.878      9451\n",
            "weighted avg      0.961     0.953     0.955      9451\n",
            "\n",
            "Sentiment model trained, evaluated, probabilities calculated, and saved.\n"
          ]
        }
      ],
      "source": [
        "def rating_to_sentiment_label(rating):\n",
        "    if rating >= 4:\n",
        "        return 'positive'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    elif rating <= 2:\n",
        "        return 'negative'\n",
        "    return None # Handle cases where rating might be NaN or unexpected value\n",
        "\n",
        "df_selected[\"__text__\"] = df_selected.apply(lambda row: build_text(safe_get(row, \"Title\"),\n",
        "                                                     safe_get(row, \"ReviewText\")), axis=1)\n",
        "# =========================================================\n",
        "# 1) Train ML Sentiment Model (multiclass)\n",
        "# =========================================================\n",
        "df_selected[\"__sentiment_label__\"] = df_selected[\"Rating\"].apply(rating_to_sentiment_label)\n",
        "\n",
        "# Use rows that have labels (rating present)\n",
        "senti_train = df_selected.dropna(subset=[\"__sentiment_label__\"]).copy()\n",
        "X_senti = senti_train[\"__text__\"].values\n",
        "y_senti = senti_train[\"__sentiment_label__\"].values\n",
        "\n",
        "# Train / test split\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X_senti, y_senti, test_size=0.2, random_state=26, stratify=y_senti\n",
        ")\n",
        "\n",
        "# TF-IDF + Logistic Regression (multiclass)\n",
        "# class_weight balances imbalanced classes\n",
        "sentiment_clf = Pipeline(steps=[\n",
        "    (\"tfidf\", TfidfVectorizer(\n",
        "        ngram_range=(1,2),\n",
        "        min_df=5,\n",
        "        max_df=0.9,\n",
        "        strip_accents=\"unicode\",\n",
        "        sublinear_tf=True\n",
        "    )),\n",
        "    (\"logreg\", LogisticRegression(\n",
        "        multi_class=\"auto\",\n",
        "        class_weight=\"balanced\",\n",
        "        solver=\"lbfgs\",\n",
        "        max_iter=200\n",
        "    ))\n",
        "])\n",
        "\n",
        "sentiment_clf.fit(X_tr, y_tr)\n",
        "y_pred = sentiment_clf.predict(X_te)\n",
        "print(\"\\n=== Sentiment classification report ===\")\n",
        "print(classification_report(y_te, y_pred, digits=3))\n",
        "\n",
        "try:\n",
        "  proba_all = sentiment_clf.predict_proba(df_selected[\"__text__\"].values)\n",
        "  # get class order\n",
        "  senti_classes = sentiment_clf.named_steps[\"logreg\"].classes_\n",
        "  # make nice probability dicts\n",
        "  prob_df = pd.DataFrame(proba_all, columns=[f\"ML_Sentiment_Prob_{c}\" for c in senti_classes])\n",
        "except Exception:\n",
        "  # fallback to decision_function (scaled to 0..1 per class via softmax)\n",
        "  from scipy.special import softmax\n",
        "  scores = sentiment_clf.decision_function(df_selected[\"__text__\"].values)\n",
        "  if scores.ndim == 1:\n",
        "      scores = np.vstack([scores, -scores]).T\n",
        "      senti_classes = np.array([\"Positive\", \"Negative\"])\n",
        "  else:\n",
        "      senti_classes = sentiment_clf.named_steps[\"logreg\"].classes_\n",
        "  proba_all = softmax(scores, axis=1);\n",
        "  prob_df = pd.DataFrame(proba_all, columns=[f\"ML_Sentiment_Prob_{c}\" for c in senti_classes])\n",
        "\n",
        "# Add probability columns to df_selected\n",
        "for c in prob_df.columns:\n",
        "        df_selected[c] = prob_df[c]\n",
        "\n",
        "senti_pred = sentiment_clf.predict(df_selected[\"__text__\"].values)\n",
        "df_selected[\"ML_Sentiment_Label\"] = senti_pred\n",
        "\n",
        "# Create a continuous score in [-1, +1] from probs:\n",
        "# Positive prob - Negative prob (Neutral reduces the magnitude naturally)\n",
        "pos_col = [c for c in prob_df.columns if c.endswith(\"positive\")] # Changed to lowercase 'positive'\n",
        "neg_col = [c for c in prob_df.columns if c.endswith(\"negative\")] # Changed to lowercase 'negative'\n",
        "pos_prob = prob_df[pos_col[0]] if pos_col else 0.0\n",
        "neg_prob = prob_df[neg_col[0]] if neg_col else 0.0\n",
        "df_selected[\"ML_Sentiment_Score\"] = (pos_prob - neg_prob).fillna(0.0)\n",
        "\n",
        "# Save sentiment model to Google Drive\n",
        "joblib.dump(sentiment_clf, \"/content/drive/MyDrive/AAI-590/models_sentiment.pkl\")\n",
        "print(\"Sentiment model trained, evaluated, probabilities calculated, and saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "453OaMe8ds-q"
      },
      "source": [
        "## Multi-Label Attribute Classification Model Training\n",
        "\n",
        "Train a multi-label classification model to identify product attributes from review text. Uses TF-IDF vectorization with OneVsRestClassifier and Logistic Regression to handle multiple simultaneous labels per review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy107dYNdZu1",
        "outputId": "7f7338a3-af5f-473d-f198-4c1d84e19a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Highlighted_Product_attributes missing/empty  generating weak labels via rules.\n",
            "\n",
            "=== Attribute multi-label model ===\n",
            "Macro-F1 (held-out): 0.941\n",
            "Label space size: 59\n",
            "Top 15 attribute labels: ['Care:notes' 'Color:bright_hi_vis' 'Color:darker' 'Color:off'\n",
            " 'Comfort:high' 'Comfort:low' 'Durability:high' 'Durability:issues'\n",
            " 'Fit:excess_length' 'Fit:loose' 'Fit:moves_in_shoe' 'Fit:noise'\n",
            " 'Fit:rides_up' 'Fit:size_issue' 'Fit:small']\n",
            "Attribute model and label binarizer trained, evaluated, and saved.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# ATTRIBUTE EXTRACTION MODEL TRAINING\n",
        "# ================================================================================\n",
        "# Train a multi-label classifier to identify product attributes from review text\n",
        "\n",
        "# Import attribute rules\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/AAI-590/')\n",
        "from attribute_rules import rules_list\n",
        "\n",
        "def compile_attribute_rules():\n",
        "    \"\"\"\n",
        "    Compile regex patterns from the rules list for efficient matching.\n",
        "    \n",
        "    Returns:\n",
        "        list: Tuples of (compiled_pattern, attribute_tag)\n",
        "    \"\"\"\n",
        "    rules = rules_list\n",
        "    return [(re.compile(pat), tag) for pat, tag in rules]\n",
        "\n",
        "# Configuration constants\n",
        "ATTR_COL = \"Highlighted_Product_attributes\"  # Column name for attribute labels\n",
        "MIN_ATTR_SUPPORT = 10  # Minimum occurrences required for an attribute to be included\n",
        "RANDOM_SEED = 26  # Random seed for reproducibility\n",
        "\n",
        "# ================================================================================\n",
        "# PREPARE LABELS FOR TRAINING\n",
        "# ================================================================================\n",
        "# Use existing attributes if available, otherwise generate weak labels using rules\n",
        "\n",
        "if ATTR_COL in df_selected.columns and df_selected[ATTR_COL].notna().any():\n",
        "    print(\"\\nUsing existing Highlighted_Product_attributes as labels for ML attribute model.\")\n",
        "    labels = df_selected[ATTR_COL].fillna(\"\").apply(lambda s: [t.strip() for t in s.split(\";\") if t.strip()])\n",
        "else:\n",
        "    print(\"\\nHighlighted_Product_attributes missing/empty  generating weak labels via rules.\")\n",
        "    compiled_rules = compile_attribute_rules()\n",
        "    labels = df_selected[\"__text__\"].apply(lambda t: extract_rule_tags(t, compiled_rules))\n",
        "\n",
        "# ================================================================================\n",
        "# FILTER ATTRIBUTES BY MINIMUM SUPPORT\n",
        "# ================================================================================\n",
        "# Keep only attributes that appear frequently enough to be meaningful\n",
        "\n",
        "attr_counts: Dict[str, int] = {}\n",
        "for tag_list in labels:\n",
        "    for t in tag_list:\n",
        "        attr_counts[t] = attr_counts.get(t, 0) + 1\n",
        "\n",
        "# Filter to common attributes (support >= MIN_ATTR_SUPPORT)\n",
        "common_attrs = {t for t, cnt in attr_counts.items() if cnt >= MIN_ATTR_SUPPORT}\n",
        "\n",
        "def filter_common(tag_list):\n",
        "    \"\"\"Filter tag list to include only common attributes.\"\"\"\n",
        "    return [t for t in tag_list if t in common_attrs]\n",
        "\n",
        "filtered_labels = labels.apply(filter_common)\n",
        "\n",
        "# ================================================================================\n",
        "# PREPARE TRAINING DATA\n",
        "# ================================================================================\n",
        "# Use only rows that have at least one label\n",
        "\n",
        "ml_rows = filtered_labels.apply(lambda lst: len(lst) > 0)\n",
        "X_attr_all = df_selected.loc[ml_rows, \"__text__\"].values\n",
        "Y_attr_all = filtered_labels.loc[ml_rows].values\n",
        "\n",
        "# Binarize multi-labels using MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y_bin = mlb.fit_transform(Y_attr_all)\n",
        "\n",
        "# ================================================================================\n",
        "# HANDLE STRATIFICATION FOR TRAIN-TEST SPLIT\n",
        "# ================================================================================\n",
        "# Remove samples with unique stratification values to enable stratified splitting\n",
        "\n",
        "# Calculate label counts per sample for stratification\n",
        "stratify_values = Y_bin.sum(axis=1)\n",
        "\n",
        "# Identify and remove samples that appear only once\n",
        "value_counts = pd.Series(stratify_values).value_counts()\n",
        "single_occurrence_values = value_counts[value_counts == 1].index\n",
        "valid_indices = ~np.isin(stratify_values, single_occurrence_values)\n",
        "\n",
        "# Filter datasets to valid indices\n",
        "X_attr_all_filtered = X_attr_all[valid_indices]\n",
        "Y_bin_filtered = Y_bin[valid_indices]\n",
        "stratify_values_filtered = stratify_values[valid_indices]\n",
        "\n",
        "# ================================================================================\n",
        "# TRAIN-TEST SPLIT\n",
        "# ================================================================================\n",
        "# Split data with stratification to maintain class distribution\n",
        "\n",
        "Xa_tr, Xa_te, Ya_tr, Ya_te = train_test_split(\n",
        "    X_attr_all_filtered, Y_bin_filtered, \n",
        "    test_size=0.2, \n",
        "    random_state=RANDOM_SEED, \n",
        "    stratify=stratify_values_filtered\n",
        ")\n",
        "\n",
        "# ================================================================================\n",
        "# BUILD AND TRAIN MODEL PIPELINE\n",
        "# ================================================================================\n",
        "# Create pipeline with TF-IDF vectorization and OneVsRestClassifier\n",
        "\n",
        "attr_clf = Pipeline(steps=[\n",
        "    (\"tfidf\", TfidfVectorizer(\n",
        "        ngram_range=(1,2),      # Use unigrams and bigrams\n",
        "        min_df=5,               # Minimum document frequency\n",
        "        max_df=0.95,            # Maximum document frequency (remove very common terms)\n",
        "        strip_accents=\"unicode\",\n",
        "        sublinear_tf=True       # Apply sublinear TF scaling\n",
        "    )),\n",
        "    (\"ovr\", OneVsRestClassifier(\n",
        "        LogisticRegression(\n",
        "            class_weight=\"balanced\",  # Handle class imbalance\n",
        "            solver=\"lbfgs\",\n",
        "            max_iter=200\n",
        "        ),\n",
        "        n_jobs=-1  # Use all available CPU cores\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "attr_clf.fit(Xa_tr, Ya_tr)\n",
        "\n",
        "# ================================================================================\n",
        "# EVALUATE MODEL PERFORMANCE\n",
        "# ================================================================================\n",
        "\n",
        "Ya_pred = attr_clf.predict(Xa_te)\n",
        "macro_f1 = f1_score(Ya_te, Ya_pred, average=\"macro\")\n",
        "\n",
        "print(f\"\\n=== Attribute multi-label model ===\\nMacro-F1 (held-out): {macro_f1:.3f}\")\n",
        "print(\"Label space size:\", len(mlb.classes_))\n",
        "print(\"Top 15 attribute labels:\", mlb.classes_[:15])\n",
        "\n",
        "# ================================================================================\n",
        "# GENERATE PREDICTIONS FOR ENTIRE DATASET\n",
        "# ================================================================================\n",
        "\n",
        "try:\n",
        "    # Get probability scores for each attribute\n",
        "    attr_proba = attr_clf.predict_proba(df_selected[\"__text__\"].values)\n",
        "except Exception:\n",
        "    # Fallback: use decision function with sigmoid transformation\n",
        "    from scipy.special import expit\n",
        "    scores = attr_clf.decision_function(attr_clf.named_steps['tfidf'].transform(df_selected[\"__text__\"].values))\n",
        "    attr_proba = expit(scores)\n",
        "\n",
        "# Apply threshold of 0.5 to convert probabilities to binary predictions\n",
        "attr_pred_bin = (attr_proba >= 0.5).astype(int)\n",
        "\n",
        "# Convert binary predictions back to attribute tag lists\n",
        "def tags_from_bin_row(bin_row):\n",
        "    \"\"\"Convert binary row to list of attribute tags.\"\"\"\n",
        "    return [mlb.classes_[i] for i, v in enumerate(bin_row) if v == 1]\n",
        "\n",
        "ml_attr_tags = [tags_from_bin_row(row) for row in attr_pred_bin]\n",
        "df_selected[\"ML_Attribute_Tags\"] = [\"; \".join(tags) for tags in ml_attr_tags]\n",
        "\n",
        "# Store raw probabilities as JSON for detailed analysis\n",
        "df_selected[\"ML_Attribute_Proba_JSON\"] = [\n",
        "    json.dumps({mlb.classes_[i]: float(p) for i, p in enumerate(attr_proba_row)}, ensure_ascii=False)\n",
        "    for attr_proba_row in attr_proba\n",
        "]\n",
        "\n",
        "# ================================================================================\n",
        "# SAVE MODEL AND LABEL BINARIZER\n",
        "# ================================================================================\n",
        "\n",
        "joblib.dump({\"pipeline\": attr_clf, \"mlb\": mlb}, \"/content/drive/MyDrive/AAI-590/models_attributes.pkl\")\n",
        "print(\"Attribute model and label binarizer trained, evaluated, and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvYUi3lmd5tF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
